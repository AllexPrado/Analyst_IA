"""
Script para sincroniza√ß√£o completa do sistema.
Este m√≥dulo implementa a sincroniza√ß√£o avan√ßada de todas as entidades do New Relic,
atualiza√ß√£o do frontend e integra√ß√£o completa dos dados.
"""

import os
import sys
import asyncio
import logging
import traceback
import json
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("logs/sincronizacao.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Garantir que o diret√≥rio de logs existe
os.makedirs("logs", exist_ok=True)

# Adicionar diret√≥rios ao path
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))
sys.path.append(str(current_dir / "backend"))

# Importar os m√≥dulos necess√°rios
from backend.utils.new_relic_full_collector import NewRelicFullCollector
from backend.utils.frontend_data_integrator import FrontendDataIntegrator

async def sincronizar_tudo(
    force_collect: bool = False,
    max_age_hours: int = 24,
    update_frontend: bool = True,
    verbose: bool = True
) -> Dict[str, Any]:
    """
    Realiza a sincroniza√ß√£o completa do sistema:
    1. Coleta todas as entidades do New Relic se necess√°rio
    2. Atualiza o frontend com os dados coletados
    3. Retorna estat√≠sticas da sincroniza√ß√£o
    
    Args:
        force_collect: Se True, for√ßa a coleta mesmo que tenha dados recentes
        max_age_hours: Idade m√°xima dos dados em horas antes de coletar novamente
        update_frontend: Se True, atualiza o frontend ap√≥s a coleta
        verbose: Se True, exibe logs detalhados
        
    Returns:
        Dict com estat√≠sticas da sincroniza√ß√£o
    """
    start_time = time.time()
    stats = {
        "start_time": datetime.now().isoformat(),
        "end_time": None,
        "duration_seconds": 0,
        "collection_performed": False,
        "frontend_updated": False,
        "errors": []
    }
    
    logger.info("=== SINCRONIZA√á√ÉO COMPLETA DO SISTEMA ANALYST_IA ===")
    
    try:
        # 1. Verificar se √© necess√°rio coletar novamente
        need_collect = force_collect
        if not need_collect:
            need_collect = verificar_necessidade_coleta(max_age_hours)
        
        # 2. Realizar coleta de dados do New Relic
        if need_collect:
            logger.info("üîÑ Iniciando coleta completa do New Relic...")
            
            # Instanciar e executar o coletor avan√ßado
            collector = NewRelicFullCollector()
            collection_stats = await collector.collect_all_data(save_to_cache=True)
            
            stats["collection_performed"] = True
            stats["collection_stats"] = collection_stats
            
            logger.info(f"‚úÖ Coleta completa finalizada. {collection_stats.get('entities_total', 0)} entidades coletadas.")
        else:
            logger.info("‚úÖ Cache atualizado encontrado. Pulando coleta.")
            stats["collection_performed"] = False
            stats["collection_stats"] = {"status": "skipped", "reason": "recent_data_available"}
        
        # 3. Atualizar frontend com os dados coletados
        if update_frontend:
            logger.info("üîÑ Atualizando frontend com os dados coletados...")
            
            # Instanciar e executar o integrador de frontend
            integrator = FrontendDataIntegrator()
            frontend_stats = await integrator.process_and_export_all_data()
            
            stats["frontend_updated"] = True
            stats["frontend_stats"] = frontend_stats
            
            logger.info(f"‚úÖ Frontend atualizado com sucesso!")
        else:
            logger.info("‚è© Atualiza√ß√£o do frontend ignorada conforme solicitado.")
            stats["frontend_updated"] = False
        
        # 4. Calcular dura√ß√£o total
        end_time = time.time()
        duration = int(end_time - start_time)
        stats["end_time"] = datetime.now().isoformat()
        stats["duration_seconds"] = duration
        
        logger.info(f"üèÅ Sincroniza√ß√£o completa finalizada em {duration} segundos")
        return stats
        
    except Exception as e:
        logger.error(f"‚ùå Erro durante a sincroniza√ß√£o: {e}")
        logger.error(traceback.format_exc())
        
        # Atualizar estat√≠sticas
        end_time = time.time()
        stats["end_time"] = datetime.now().isoformat()
        stats["duration_seconds"] = int(end_time - start_time)
        stats["success"] = False
        stats["errors"].append(str(e))
        stats["error_traceback"] = traceback.format_exc()
        
        return stats

def verificar_necessidade_coleta(max_age_hours: int = 24) -> bool:
    """
    Verifica se √© necess√°rio realizar uma nova coleta baseado na idade do cache.
    
    Args:
        max_age_hours: Idade m√°xima dos dados em horas antes de coletar novamente
        
    Returns:
        True se for necess√°rio coletar, False caso contr√°rio
    """
    try:
        # Verificar se o relat√≥rio de cobertura existe
        cache_dir = Path("cache") / "newrelic"
        coverage_file = cache_dir / "coverage_report.json"
        
        if not coverage_file.exists():
            logger.info("Relat√≥rio de cobertura n√£o encontrado. Coleta necess√°ria.")
            return True
        
        # Verificar a idade do relat√≥rio
        with open(coverage_file, "r", encoding="utf-8") as f:
            coverage_data = json.load(f)
        
        last_updated_str = coverage_data.get("timestamp")
        if not last_updated_str:
            logger.info("Timestamp n√£o encontrado no relat√≥rio. Coleta necess√°ria.")
            return True
        
        try:
            last_updated = datetime.fromisoformat(last_updated_str)
            now = datetime.now()
            age_hours = (now - last_updated).total_seconds() / 3600
            
            if age_hours > max_age_hours:
                logger.info(f"Dados com {age_hours:.1f} horas de idade (limite: {max_age_hours}). Coleta necess√°ria.")
                return True
            else:
                logger.info(f"Dados atualizados h√° {age_hours:.1f} horas (dentro do limite de {max_age_hours}). Coleta n√£o necess√°ria.")
                return False
                
        except Exception as e:
            logger.warning(f"Erro ao analisar timestamp: {e}. For√ßando coleta.")
            return True
            
    except Exception as e:
        logger.warning(f"Erro ao verificar necessidade de coleta: {e}. For√ßando coleta.")
        return True

async def atualizar_frontend():
    """
    Atualiza apenas o frontend com os dados j√° coletados.
    """
    try:
        logger.info("üîÑ Atualizando frontend com os dados existentes...")
        
        # Instanciar e executar o integrador de frontend
        integrator = FrontendDataIntegrator()
        frontend_stats = await integrator.process_and_export_all_data()
        
        logger.info(f"‚úÖ Frontend atualizado com sucesso!")
        return {"success": True, "stats": frontend_stats}
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao atualizar frontend: {e}")
        logger.error(traceback.format_exc())
        return {"success": False, "error": str(e)}

async def main():
    """Fun√ß√£o principal para execu√ß√£o direta do script"""
    import argparse
    
    # Configurar argumentos de linha de comando
    parser = argparse.ArgumentParser(description='Sincroniza√ß√£o completa do sistema Analyst_IA')
    parser.add_argument('--force', action='store_true', help='For√ßar coleta mesmo que tenha dados recentes')
    parser.add_argument('--max-age', type=int, default=24, help='Idade m√°xima dos dados em horas antes de coletar novamente')
    parser.add_argument('--no-frontend', action='store_true', help='N√£o atualizar o frontend ap√≥s a coleta')
    parser.add_argument('--frontend-only', action='store_true', help='Apenas atualizar o frontend, sem coletar dados')
    parser.add_argument('--verbose', action='store_true', help='Exibir logs detalhados')
    
    args = parser.parse_args()
    
    if args.frontend_only:
        # Apenas atualizar o frontend
        await atualizar_frontend()
    else:
        # Sincronizar tudo
        await sincronizar_tudo(
            force_collect=args.force, 
            max_age_hours=args.max_age,
            update_frontend=not args.no_frontend,
            verbose=args.verbose
        )

if __name__ == "__main__":
    asyncio.run(main())
