"""
Script para testar as melhorias implementadas no Chat IA
Verifica a qualidade das respostas ap√≥s as modifica√ß√µes
"""

import asyncio
import logging
import json
import sys
import re
from pathlib import Path
from datetime import datetime

# Configura√ß√£o do logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Adiciona pasta atual ao path para importar m√≥dulos locais
sys.path.append(str(Path(__file__).parent))

class ChatInput:
    def __init__(self, pergunta):
        self.pergunta = pergunta

async def testar_chat_melhorado():
    """
    Testa o chat com diferentes perguntas e avalia a qualidade das respostas
    ap√≥s as melhorias implementadas.
    """
    try:
        print("\n" + "="*80)
        print(" üî¨ INICIANDO TESTE DO CHAT IA MELHORADO")
        print("="*80)
        
        # Importa o endpoint de chat
        from backend.main import chat_endpoint
        
        # Lista de perguntas para testar diferentes cen√°rios
        perguntas = [
            "Quais s√£o os servi√ßos mais cr√≠ticos neste momento?",
            "H√° algum padr√£o de erro comum entre as entidades com problemas?",
            "Qual a tend√™ncia de performance do sistema nas √∫ltimas horas?",
            "Compare o desempenho entre os diferentes dom√≠nios monitorados",
            "Qual a correla√ß√£o entre uso de CPU e erros reportados?"
        ]
        
        resultados = []
        
        for i, pergunta in enumerate(perguntas):
            print(f"\nüìù Teste {i+1}/{len(perguntas)}: \"{pergunta}\"")
            
            # Chama o endpoint do chat
            inicio = datetime.now()
            resposta = await chat_endpoint(ChatInput(pergunta))
            fim = datetime.now()
            tempo_resposta = (fim - inicio).total_seconds()
            
            if not resposta or not hasattr(resposta, "resposta"):
                print(f"   ‚ùå Erro: Resposta inv√°lida")
                continue
                
            # Analisa a resposta
            resposta_texto = resposta.resposta
            
            # Estat√≠sticas b√°sicas
            tamanho = len(resposta_texto)
            linhas = resposta_texto.count("\n") + 1
            palavras = len(re.findall(r'\w+', resposta_texto))
            
            # Verifica se √© uma resposta gen√©rica ou de fallback
            respostas_genericas = [
                "n√£o tenho dados",
                "n√£o possuo informa√ß√µes",
                "n√£o foi poss√≠vel encontrar",
                "n√£o h√° dados",
                "n√£o sei responder",
                "n√£o tenho informa√ß√µes suficientes",
                "sem dados dispon√≠veis",
                "preciso de mais informa√ß√µes"
            ]
            
            generica = any(frase.lower() in resposta_texto.lower() for frase in respostas_genericas)
            
            # Verificar se cont√©m informa√ß√µes t√©cnicas
            contem_metricas = any(termo in resposta_texto.lower() for termo in 
                               ["apdex", "lat√™ncia", "erro", "throughput", "cpu", "mem√≥ria", "disponibilidade"])
            contem_nrql = "NRQL" in resposta_texto or ("SELECT" in resposta_texto and "FROM" in resposta_texto)
            
            # Verificar se cont√©m estrutura de an√°lise
            contem_diagnostico = "diagn√≥stico" in resposta_texto.lower() or "an√°lise" in resposta_texto.lower()
            contem_recomendacao = "recomend" in resposta_texto.lower() or "sugest" in resposta_texto.lower()
            
            # Qualidade t√©cnica da resposta (baseada em heur√≠sticas)
            score_tecnico = 0
            if contem_metricas: score_tecnico += 1
            if contem_nrql: score_tecnico += 1
            if contem_diagnostico: score_tecnico += 1
            if contem_recomendacao: score_tecnico += 1
            if not generica: score_tecnico += 1
            
            nivel_tecnico = "Baixo" if score_tecnico <= 1 else ("M√©dio" if score_tecnico <= 3 else "Alto")
            
            # Resumo da an√°lise
            print(f"   ‚è±Ô∏è Tempo de resposta: {tempo_resposta:.2f}s")
            print(f"   üìä Tamanho: {tamanho} caracteres, {palavras} palavras, {linhas} linhas")
            print(f"   üìä Resposta gen√©rica: {'Sim ‚ö†Ô∏è' if generica else 'N√£o ‚úÖ'}")
            print(f"   üìä Cont√©m m√©tricas: {'Sim ‚úÖ' if contem_metricas else 'N√£o ‚ö†Ô∏è'}")
            print(f"   üìä Cont√©m NRQL: {'Sim ‚úÖ' if contem_nrql else 'N√£o'}")
            print(f"   üìä Cont√©m diagn√≥stico: {'Sim ‚úÖ' if contem_diagnostico else 'N√£o ‚ö†Ô∏è'}")
            print(f"   üìä Cont√©m recomenda√ß√µes: {'Sim ‚úÖ' if contem_recomendacao else 'N√£o ‚ö†Ô∏è'}")
            print(f"   üéì N√≠vel t√©cnico: {nivel_tecnico}")
            
            # Fragmento da resposta
            fragmento = resposta_texto[:150].replace("\n", " ") + "..." if len(resposta_texto) > 150 else resposta_texto
            print(f"   üí¨ Fragmento: \"{fragmento}\"")
            
            # Armazena resultados para an√°lise comparativa
            resultados.append({
                "pergunta": pergunta,
                "tempo_resposta": tempo_resposta,
                "tamanho": tamanho,
                "palavras": palavras,
                "generica": generica,
                "contem_metricas": contem_metricas,
                "contem_nrql": contem_nrql,
                "contem_diagnostico": contem_diagnostico,
                "contem_recomendacao": contem_recomendacao,
                "nivel_tecnico": nivel_tecnico,
                "score_tecnico": score_tecnico
            })
        
        # An√°lise comparativa
        if resultados:
            print("\n" + "="*80)
            print(" üìä AN√ÅLISE COMPARATIVA")
            print("="*80)
            
            avg_tempo = sum(r["tempo_resposta"] for r in resultados) / len(resultados)
            avg_tamanho = sum(r["tamanho"] for r in resultados) / len(resultados)
            avg_palavras = sum(r["palavras"] for r in resultados) / len(resultados)
            avg_score = sum(r["score_tecnico"] for r in resultados) / len(resultados)
            
            print(f"Tempo m√©dio de resposta: {avg_tempo:.2f}s")
            print(f"Tamanho m√©dio: {avg_tamanho:.0f} caracteres, {avg_palavras:.0f} palavras")
            print(f"Score t√©cnico m√©dio: {avg_score:.1f}/5")
            print(f"Respostas gen√©ricas: {sum(1 for r in resultados if r['generica'])}/{len(resultados)}")
            print(f"Respostas com diagn√≥stico: {sum(1 for r in resultados if r['contem_diagnostico'])}/{len(resultados)}")
            print(f"Respostas com recomenda√ß√µes: {sum(1 for r in resultados if r['contem_recomendacao'])}/{len(resultados)}")
            
            # Salva os resultados em um arquivo para refer√™ncia
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            with open(f"logs/teste_chat_{timestamp}.json", "w", encoding="utf-8") as f:
                json.dump(resultados, f, indent=2, ensure_ascii=False)
            print(f"\nResultados salvos em: logs/teste_chat_{timestamp}.json")
        
        print("\n" + "="*80)
        print(" ‚úÖ TESTE DO CHAT CONCLU√çDO")
        print("="*80)
        
    except Exception as e:
        logger.error(f"Erro ao testar chat: {e}", exc_info=True)
        print(f"\n‚ùå ERRO NO TESTE: {str(e)}")
        return False
    
    return True

if __name__ == "__main__":
    asyncio.run(testar_chat_melhorado())
