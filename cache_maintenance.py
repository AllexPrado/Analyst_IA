"""
Script para testar, manter e corrigir o sistema de cache.
Este script permite verificar, inicializar e corrigir o cache do Analyst IA.
"""

import os
import sys
import asyncio
import json
import logging
import argparse
from datetime import datetime
from pathlib import Path

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Adiciona diret√≥rios ao path
current_dir = Path(__file__).parent
if current_dir.name == "backend":
    sys.path.append(str(current_dir.parent))
else:
    sys.path.append(str(current_dir))
    backend_dir = current_dir / "backend"
    if backend_dir.exists():
        sys.path.append(str(backend_dir))

try:
    # Importa√ß√µes do sistema de cache
    from backend.utils.cache import (
        get_cache, forcar_atualizacao_cache, diagnosticar_cache,
        carregar_cache_do_disco, salvar_cache_no_disco
    )
    from backend.utils.cache_advanced import (
        inicializar_sistema_cache, status_cache, 
        coletar_contexto_completo_avancado
    )
    from backend.utils.cache_initializer import verificar_integridade_cache
    from backend.utils.entity_processor import filter_entities_with_data
    
    logger.info("M√≥dulos importados com sucesso")
except ImportError as e:
    logger.error(f"Erro ao importar m√≥dulos: {e}")
    sys.exit(1)

async def verificar_cache():
    """Verifica o estado atual do cache"""
    logger.info("Verificando estado do cache...")
    
    # Diagn√≥stico padr√£o
    diag = diagnosticar_cache()
    print("\n== DIAGN√ìSTICO DO CACHE ==")
    print(f"Status: {diag.get('status', 'Desconhecido')}")
    print(f"√öltima atualiza√ß√£o: {diag.get('ultima_atualizacao', 'Nunca')}")
    if 'idade_horas' in diag:
        print(f"Idade: {diag['idade_horas']:.2f} horas")
    
    print(f"Total de chaves: {diag.get('total_chaves_dados', 0)}")
    print(f"Chaves: {diag.get('chaves_dados', [])}")
    print(f"Tamanho em disco: {diag.get('tamanho_disco_mb', 0):.2f} MB")
    
    # Diagn√≥stico avan√ßado
    integridade = await verificar_integridade_cache()
    print("\n== INTEGRIDADE DO CACHE ==")
    print(f"Arquivo: {integridade['arquivo_cache']}")
    print(f"Existe: {integridade['arquivo_existe']}")
    print(f"Integridade: {integridade['integridade']}")
    print(f"Total de entidades: {integridade['total_entidades']}")
    print(f"Erros: {integridade['erros']}")
    
    if integridade['entidades_por_dominio']:
        print("\n== ENTIDADES POR DOM√çNIO ==")
        for dominio, contagem in integridade['entidades_por_dominio'].items():
            print(f"{dominio}: {contagem}")
    
    # Verificar cache atual
    cache = await get_cache(forcar_atualizacao=False)
    entidades = cache.get("entidades", [])
    
    if entidades:
        print(f"\nTotal de {len(entidades)} entidades no cache")
        
        # Verifica qualidade dos dados
        entidades_com_dados = filter_entities_with_data(entidades)
        print(f"Entidades com dados v√°lidos: {len(entidades_com_dados)} de {len(entidades)} ({len(entidades_com_dados)/len(entidades)*100:.1f}%)")
    else:
        print("\nNenhuma entidade no cache")

async def inicializar():
    """Inicializa o sistema de cache avan√ßado"""
    logger.info("Inicializando sistema de cache avan√ßado...")
    
    try:
        resultado = await inicializar_sistema_cache()
        if resultado:
            print("\n‚úÖ Sistema de cache inicializado com sucesso!")
        else:
            print("\n‚ùå Falha ao inicializar sistema de cache")
    except Exception as e:
        logger.error(f"Erro ao inicializar cache: {e}")
        print(f"\n‚ùå Erro ao inicializar cache: {e}")

async def forcar_atualizacao():
    """For√ßa uma atualiza√ß√£o completa do cache"""
    logger.info("For√ßando atualiza√ß√£o do cache...")
    
    try:
        print("Atualizando cache... (pode levar alguns minutos)")
        start_time = datetime.now()
        
        resultado = await forcar_atualizacao_cache(coletar_contexto_completo_avancado)
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        if resultado:
            print(f"\n‚úÖ Cache atualizado com sucesso em {duration:.2f} segundos!")
            
            # Verificar resultados
            cache = await get_cache(forcar_atualizacao=False)
            entidades = cache.get("entidades", [])
            print(f"Total de {len(entidades)} entidades no cache")
            
            # Contar por dom√≠nio
            dominios = {}
            for e in entidades:
                dominio = e.get('domain', 'Desconhecido')
                dominios[dominio] = dominios.get(dominio, 0) + 1
            
            print("\nEntidades por dom√≠nio:")
            for dominio, contagem in dominios.items():
                print(f"- {dominio}: {contagem}")
        else:
            print("\n‚ùå Falha ao atualizar o cache")
    except Exception as e:
        logger.error(f"Erro ao atualizar cache: {e}")
        print(f"\n‚ùå Erro ao atualizar cache: {e}")

async def exportar_cache(caminho):
    """Exporta o cache atual para um arquivo JSON"""
    logger.info(f"Exportando cache para {caminho}...")
    
    try:
        cache = await get_cache(forcar_atualizacao=False)
        
        # Salvar em arquivo
        with open(caminho, 'w', encoding='utf-8') as f:
            json.dump(cache, f, indent=2, ensure_ascii=False)
        
        print(f"\n‚úÖ Cache exportado para {caminho}")
        print(f"Tamanho do arquivo: {os.path.getsize(caminho) / (1024*1024):.2f} MB")
    except Exception as e:
        logger.error(f"Erro ao exportar cache: {e}")
        print(f"\n‚ùå Erro ao exportar cache: {e}")

async def stats_cache():
    """Mostra estat√≠sticas detalhadas do cache"""
    logger.info("Gerando estat√≠sticas do cache...")
    
    try:
        cache = await get_cache(forcar_atualizacao=False)
        entidades = cache.get("entidades", [])
        
        if not entidades:
            print("\n‚ö†Ô∏è Nenhuma entidade no cache")
            return
            
        # Estat√≠sticas b√°sicas
        print("\n== ESTAT√çSTICAS DO CACHE ==")
        print(f"Total de entidades: {len(entidades)}")
        timestamp = cache.get("timestamp", "Desconhecido")
        print(f"Timestamp: {timestamp}")
        
        try:
            ts = datetime.fromisoformat(timestamp)
            idade = (datetime.now() - ts).total_seconds() / 3600
            print(f"Idade: {idade:.2f} horas")
        except:
            print("N√£o foi poss√≠vel calcular idade do cache")
        
        # Entidades por dom√≠nio
        dominios = {}
        tipos = {}
        entidades_com_metricas = 0
        total_metricas = 0
        
        for e in entidades:
            # Contar por dom√≠nio
            dominio = e.get('domain', 'Desconhecido')
            dominios[dominio] = dominios.get(dominio, 0) + 1
            
            # Contar por tipo
            tipo = e.get('entityType', 'Desconhecido')
            tipos[tipo] = tipos.get(tipo, 0) + 1
            
            # Contar m√©tricas
            metricas = e.get('metricas', {})
            if metricas:
                entidades_com_metricas += 1
                
                for periodo, valores in metricas.items():
                    total_metricas += sum(1 for v in valores.values() if v is not None)
        
        print("\n== ENTIDADES POR DOM√çNIO ==")
        for dominio, contagem in sorted(dominios.items(), key=lambda x: x[1], reverse=True):
            print(f"{dominio}: {contagem}")
        
        print("\n== ENTIDADES POR TIPO ==")
        for tipo, contagem in sorted(tipos.items(), key=lambda x: x[1], reverse=True)[:10]:  # Top 10
            print(f"{tipo}: {contagem}")
        
        print("\n== M√âTRICAS ==")
        print(f"Entidades com m√©tricas: {entidades_com_metricas} de {len(entidades)} ({entidades_com_metricas/len(entidades)*100:.1f}%)")
        print(f"Total de valores de m√©tricas: {total_metricas}")
        print(f"M√©dia de m√©tricas por entidade: {total_metricas/len(entidades):.2f}")
        
    except Exception as e:
        logger.error(f"Erro ao gerar estat√≠sticas: {e}")
        print(f"\n‚ùå Erro ao gerar estat√≠sticas: {e}")

async def main():
    parser = argparse.ArgumentParser(description="Ferramenta de manuten√ß√£o do cache do Analyst IA")
    parser.add_argument("--verificar", action="store_true", help="Verificar estado atual do cache")
    parser.add_argument("--inicializar", action="store_true", help="Inicializar sistema de cache avan√ßado")
    parser.add_argument("--atualizar", action="store_true", help="For√ßar atualiza√ß√£o do cache")
    parser.add_argument("--exportar", metavar="CAMINHO", help="Exportar cache para arquivo JSON")
    parser.add_argument("--stats", action="store_true", help="Mostrar estat√≠sticas detalhadas do cache")
    
    args = parser.parse_args()
    
    print("===================================================")
    print("üîß FERRAMENTA DE MANUTEN√á√ÉO DO CACHE - ANALYST IA")
    print("===================================================")
    
    # Se nenhum argumento for fornecido, mostre o status
    if not any([args.verificar, args.inicializar, args.atualizar, args.exportar, args.stats]):
        args.verificar = True
    
    # Executar opera√ß√µes solicitadas
    if args.verificar:
        await verificar_cache()
        
    if args.inicializar:
        await inicializar()
        
    if args.atualizar:
        await forcar_atualizacao()
        
    if args.exportar:
        await exportar_cache(args.exportar)
        
    if args.stats:
        await stats_cache()
    
    print("\n===================================================")
    print("üèÅ OPERA√á√ïES CONCLU√çDAS")
    print("===================================================")

if __name__ == "__main__":
    asyncio.run(main())
